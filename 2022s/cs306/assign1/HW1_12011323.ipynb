{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KDD Assignment 1\n",
    "![CS306](https://img.shields.io/badge/CS306-Data%20Mining-orange) &nbsp;\n",
    "![2022s](https://img.shields.io/badge/semester-2022%20spring-blue)\n",
    "\n",
    "Author: 何泽安 (He Zean) &nbsp;&nbsp; SID: 12011323"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Read the Data\n",
    "\n",
    "When we simply use `pd.read_csv('HW1data.csv')` to read the data, we will get a `UnicodeDecodeError`, which means we need first to detect the actual encoding of this file (instead of the default UTF-8).\n",
    "> requiring `chardet` >= 4.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet\n",
    "\n",
    "with open('HW1data.csv', 'rb') as f:\n",
    "    enc = chardet.detect(f.read(1000))['encoding']  # give chardet 1000 bytes to let it guess is enough\n",
    "\n",
    "print(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('HW1data.csv', encoding=enc)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have successfully loaded the data with pandas, we can check if there exists any missing values.\n",
    "\n",
    "The following result shows that for all the 14 columns, about `9.5%` of the data is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum() / len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Attempt to Complement the Missing Values\n",
    "\n",
    "### (a) Extract `{PatientId-Gender-Age-Neighbourhood}`\n",
    "\n",
    "The point is, one patient may have multiple records (check this by calling `data['PatientId'].nunique()`), therefore the `patient_base_info`, which views the PatientId as the primary key, should be `groupby` the id first.\n",
    "\n",
    "When we are aggregating the data, we notice that the `age` of a patiend is not always consistent, so we need to use the mean value to represent it, while other two features are not numeric, and we cannot judge if there are some inconsistents easily, we tend to use `first` to aggregate them.\n",
    "\n",
    "We thus find out that there are 62299 patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_base_info = data[['PatientId', 'Gender', 'Age', 'Neighbourhood']] \\\n",
    "    .groupby('PatientId') \\\n",
    "    .agg({'Gender': 'first',             # use the first non n/a value to repr the patiend's gender\n",
    "          'Age': 'mean',                 # for some patients, their age are not consistent, let's take their avg\n",
    "          'Neighbourhood': 'first'})     # use the first non n/a value to repr the patiend's meighbourhood\n",
    "patient_base_info.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Drop the Missing Values of Some Columns\n",
    "\n",
    "Now, all the rows where any of `PatientID`, `ScheduledDay`, `AppointmentDay`, `SMS_received` or `No-show` is missed are removed.\n",
    "\n",
    "Note that the number of columns is reduced from `667536` (see code cell 2) to `413654`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(subset=['PatientId', 'ScheduledDay', 'AppointmentDay', 'SMS_received', 'No-show'], inplace=True)  # any record that missing any of these `key` columns contribute nothing for the further module training\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Use the Previously Extracted Info to Complete the Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we no more need the origin data, since patient_base_info has its backup\n",
    "data.drop(['Gender', 'Age', 'Neighbourhood'], axis=1, inplace=True)\n",
    "\n",
    "res = pd.merge(data, patient_base_info, on='PatientId')\n",
    "res.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Another `dropna`\n",
    "\n",
    "Actually do no effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.dropna(subset=['PatientId', 'Gender', 'Age', 'Neighbourhood',\n",
    "           'ScheduledDay', 'AppointmentDay', 'SMS_received', 'No-show'], inplace=True)\n",
    "# actually affect nothing, since there is no NaN for these cols\n",
    "\n",
    "res.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Fill the Missing Values with Default Value `0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.fillna({'Scholarship': 0,\n",
    "            'Hipertension': 0,\n",
    "            'Diabetes': 0,\n",
    "            'Alcoholism': 0,\n",
    "            'Handcap': 0},\n",
    "           inplace=True)  # as mentioned in the docs\n",
    "res.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Drop the Unused Features `PatientId` and `AppointmentID`\n",
    "\n",
    "So far so good, now we have a nicely dataframe with no missing values!\n",
    "\n",
    "> As the group chat mentioned, some `PatientId` are floating point numbers, but it actually does not affect the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.drop(['PatientId', 'AppointmentID'], axis=1, inplace=True)  # these id was for merging and cleaning the data, but contributes nothing for our module\n",
    "res.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6. Drop the \"Dirty Records\"\n",
    "\n",
    "Let's glance at the dataframe first. We can easily find a trival dissonant tone, `Age.min`! Let's throw them away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the Dtype from object to datetime64, let pandas better analyzing the data\n",
    "res['ScheduledDay'] = pd.to_datetime(res['ScheduledDay'])\n",
    "res['AppointmentDay'] = pd.to_datetime(res['AppointmentDay'])\n",
    "\n",
    "res.describe(include='all', datetime_is_numeric=True)  # then check the table manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.drop(res[res['Age'] < 0].index, inplace=True)  # age < 0 must be invalid\n",
    "res.info()  # 4 dirty records are removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's think deeper: Scholarship, Hipertension... they are all numerical features, it's really hard for us to judge if they are invalid or not. But since we just parsed `ScheduledDay` and `AppointmentDay`, why not also check them?\n",
    "\n",
    "When a patient making an schedule online, of cause he/she could not appointes to the day before that day. Here are about 82.6% of the records violating this rule and thus need to be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(res[res['ScheduledDay'] > res['AppointmentDay']]) / len(res))  # percentage of records containing invalid schedule day\n",
    "res.drop(res[res['ScheduledDay'] > res['AppointmentDay']].index, inplace=True)  # schedule to a day before appointment is not possible\n",
    "res.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7. Calculate the `Delta_Day`\n",
    "\n",
    "We need a number to represent the number of days between the `ScheduledDay` and `AppointmentDay`, instead of a precise timedelta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['Delta_Day'] = (res['AppointmentDay'] - res['ScheduledDay']).astype('timedelta64[D]')  # only take the number of days\n",
    "res['Delta_Day'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8. Find the Day of Week for `ScheduledDay` and `AppointmentDay`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['SDay_DOW'] = res['ScheduledDay'].dt.dayofweek\n",
    "res['ADay_DOW'] = res['AppointmentDay'].dt.dayofweek\n",
    "\n",
    "print(res['SDay_DOW'].value_counts())  # most patients schedule on Monday\n",
    "print(res['ADay_DOW'].value_counts())  # most patients appointment on Tuesday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9. Remove the Raw Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.drop(['ScheduledDay', 'AppointmentDay'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enjoy Our Dog Food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.describe(include='all', datetime_is_numeric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.head(20)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4db10295a3c57a5ad8255c01fd3ebaa9f6abf6ad4aa73f33b05d7aca9721ddfb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
